{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stability Evaluation\n",
    "> Author: Tianyu Lin\n",
    ">\n",
    "> Email: linty6@mail2.sysu.edu.cn\n",
    "> \n",
    "> Date: Mar 2, 2024\n",
    "\n",
    "### Introduction\n",
    "Evaluate the stability of segmentation results of diffusion-based segmentation models.\n",
    "\n",
    "### Metrics\n",
    "1. FID(deleted) & LPIPS: calculate between each set of predictions of the whole test dataset. \n",
    "2. SSIM & MS-SSIM & PSNR: calculate between each predictions of a fixed image in test dataset.\n",
    "\n",
    "### GPU Memory Requirements\n",
    "> Calculate the metrics on cuda for acceleration.\n",
    "\n",
    "For BTCV slices (with non-empty label, 847 images x 10), requires 6GB == 3GB (for data) + 3GB (for LPIPS model with batch_size 50).\n",
    "\n",
    "### Notes\n",
    "- Reults to be estimated should not contain empty prediction.\n",
    "- Put your results as:\n",
    "```bash\n",
    "outputs/\n",
    "├── slice2seg-samples-dataset_name\n",
    "│   ├── seed1\n",
    "│   │   ├── file1-gts.png\n",
    "│   │   ├── file2-gts.png\n",
    "│   │   ├── file3-gts.png\n",
    "│   │   ├── ...\n",
    "│   ├── seed2\n",
    "│   │   ├── file1-gts.png\n",
    "│   │   ├── file2-gts.png\n",
    "│   │   ├── file3-gts.png\n",
    "│   │   ├── ...\n",
    "│   ├── ...\n",
    "```\n",
    "And modify the 'paths' in the \"Preparation\" code block if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/GPUFS/nsccgz_ywang_zfd/.conda/envs/ldm/lib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/GPUFS/nsccgz_ywang_zfd/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"seaborn\")\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "if 'LD_LIBRARY_PATH' not in os.environ:\n",
    "    os.environ[\"LD_LIBRARY_PATH\"] = f\"/GPUFS/nsccgz_ywang_zfd/.conda/envs/ldm/lib\"\n",
    "else:\n",
    "    os.environ[\"LD_LIBRARY_PATH\"] = f\"/GPUFS/nsccgz_ywang_zfd/.conda/envs/ldm/lib:{os.environ['LD_LIBRARY_PATH']}\"\n",
    "print(os.environ[\"LD_LIBRARY_PATH\"])\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchmetrics.image.lpip import LearnedPerceptualImagePatchSimilarity as LPIPS\n",
    "# from torchmetrics.image.fid import FrechetInceptionDistance as FID\n",
    "from torchmetrics.image import StructuralSimilarityIndexMeasure as SSIM\n",
    "from torchmetrics.image import MultiScaleStructuralSimilarityIndexMeasure as MSSSIM\n",
    "from torchmetrics.image import PeakSignalNoiseRatio as PSNR\n",
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(seeds, samples) = (10, 847)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images: 100%|██████████| 8470/8470 [05:46<00:00, 24.47it/s]\n",
      "Preparing list per test set: 100%|██████████| 10/10 [00:00<00:00, 86659.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 torch.Size([847, 3, 256, 256]) torch.uint8 tensor(0, device='cuda:0', dtype=torch.uint8) tensor(255, device='cuda:0', dtype=torch.uint8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing list per cond: 100%|██████████| 847/847 [00:00<00:00, 318959.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "847 torch.Size([10, 3, 256, 256]) torch.uint8 tensor(0, device='cuda:0', dtype=torch.uint8) tensor(255, device='cuda:0', dtype=torch.uint8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class LPIPSDataset(Dataset):    # cut dataset to batches for LPIPS model\n",
    "    def __init__(self, data_list) -> None:\n",
    "        super().__init__()\n",
    "        self.data_list = data_list\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_list[idx]\n",
    "    def __len__(self):\n",
    "        return self.data_list.shape[0]\n",
    "    \n",
    "    \n",
    "\"\"\"Set parameters & paths\"\"\"\n",
    "plot = False    # plot metric values curve\n",
    "eval_path = \"../outputs/slice2seg-samples-synapse-b\"  # SDSeg\n",
    "# eval_path = \"/GPUFS/nsccgz_ywang_zfd/LinTianyu/Internship/Diff-UNet-main/BTCV/logs_btcv/compare\"    # Diff-UNet\n",
    "# eval_path = \"/GPUFS/nsccgz_ywang_zfd/LinTianyu/Internship/MedSegDiff-master/results/BTCV_test/dpmsolver_50_10_save\" # MedSegDiff-V2\n",
    "\n",
    "\n",
    "\"\"\"Parse image paths\"\"\"\n",
    "seed_folders = glob.glob(os.path.join(eval_path, \"[0-9]\"))  # seed 0 to 9\n",
    "path_array = np.asarray(list(map(lambda x: glob.glob(os.path.join(x, \"*-logits*\")), seed_folders)))    # *-gts contains only non-empty target slice\n",
    "num_samples, num_test_set = path_array.shape\n",
    "print(f\"(seeds, samples) = {num_samples, num_test_set}\")\n",
    "\n",
    "\n",
    "\"\"\"Loading all images\"\"\"\n",
    "pred_array = list()\n",
    "for path in tqdm(path_array.flatten(), desc=\"Loading images\"):\n",
    "    pred_array.append(np.asarray(Image.open(path).convert(\"RGB\")))\n",
    "pred_array = np.asarray(pred_array)\n",
    "image_shape = pred_array.shape[1:]  # h w c\n",
    "pred_array = torch.from_numpy(\n",
    "    np.asarray(pred_array).reshape(num_samples, num_test_set, *image_shape)\n",
    "    )\n",
    "pred_array = pred_array.permute(0, 1, 4, 2, 3).cuda()\n",
    "\n",
    "\n",
    "\"\"\"for LPIPS:  each element refers to one time of inference on the test set\"\"\"\n",
    "pred_test_set_list = list()\n",
    "for idx in tqdm(range(num_samples), desc=\"Preparing list per test set\"):\n",
    "    pred_test_set_list.append(pred_array[idx])\n",
    "print(len(pred_test_set_list), pred_test_set_list[0].shape, pred_test_set_list[0].dtype, pred_test_set_list[0].min(), pred_test_set_list[0].max())\n",
    "\n",
    "\n",
    "\"\"\"for SSIM & PNSR & MS-SSIM:  each element refers to several samples on an single imagepred_test_set_list = list()\"\"\"\n",
    "pred_samples_list = list()\n",
    "for idx in tqdm(range(num_test_set), desc=\"Preparing list per cond\"):\n",
    "    pred_samples_list.append(pred_array[:, idx])\n",
    "print(len(pred_samples_list), pred_samples_list[0].shape, pred_samples_list[0].dtype, pred_samples_list[0].min(), pred_samples_list[0].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MS-SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/GPUFS/nsccgz_ywang_zfd/.conda/envs/ldm/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `MS_SSIM` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "MS-SSIM Evaluation: 100%|██████████| 847/847 [00:33<00:00, 25.63it/s, MS_SSIM_per_cond=0.993]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m mean MS-SSIM = 0.9855666160583496\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "msssim = MSSSIM()   # input: (N, 3, H, W)\n",
    "msssim.cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    msssim_values = list()\n",
    "    pbar = tqdm(pred_samples_list, desc=\"MS-SSIM Evaluation\")\n",
    "    for pred_per_cond in pbar:  \n",
    "        if pred_per_cond[0:1].sum()==0:     # prevent Division by Zero \n",
    "            continue\n",
    "        msssim_per_cond = list() \n",
    "        for i in range(1, num_samples):\n",
    "            if pred_per_cond[i:i+1].sum()==0:   # prevent Division by Zero \n",
    "                continue\n",
    "            msssim.update(pred_per_cond[i:i+1].float(), pred_per_cond[0:1].float())\n",
    "            msssim_i = msssim.compute().cpu()\n",
    "            msssim.reset()\n",
    "\n",
    "            msssim_per_cond.append(msssim_i)\n",
    "\n",
    "        if len(msssim_per_cond) > 0:    \n",
    "            msssim_per_cond = np.asarray(msssim_per_cond)\n",
    "            msssim_values.append(msssim_per_cond.mean())\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        pbar.set_postfix(MS_SSIM_per_cond=msssim_per_cond.mean())\n",
    "\n",
    "msssim_values = np.asarray(msssim_values)\n",
    "msssim.cpu()\n",
    "\n",
    "print(f\"\\033[31m mean MS-SSIM = {msssim_values.mean()}\\033[0m\")\n",
    "\n",
    "if plot:\n",
    "    plt.plot(msssim_values, \"o-\")\n",
    "    plt.show()\n",
    "    plt.clf()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SSIM score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/GPUFS/nsccgz_ywang_zfd/.conda/envs/ldm/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `SSIM` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "SSIM Evaluation: 100%|██████████| 847/847 [00:09<00:00, 92.10it/s, SSIM_per_cond=0.922] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m mean SSIM = 0.9450787305831909\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ssim = SSIM()   # input: (N, 3, H, W)\n",
    "ssim.cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    ssim_values = list()\n",
    "    pbar = tqdm(pred_samples_list, desc=\"SSIM Evaluation\")\n",
    "    for pred_per_cond in pbar:  \n",
    "        if pred_per_cond[0:1].sum()==0:     # prevent Division by Zero \n",
    "            continue\n",
    "        ssim_per_cond = list() \n",
    "        for i in range(1, num_samples):\n",
    "            if pred_per_cond[i:i+1].sum()==0:   # prevent Division by Zero \n",
    "                continue\n",
    "            ssim.update(pred_per_cond[i:i+1].float(), pred_per_cond[0:1].float())\n",
    "            ssim_i = ssim.compute().cpu()\n",
    "            ssim.reset()\n",
    "\n",
    "            ssim_per_cond.append(ssim_i)\n",
    "        if len(ssim_per_cond) > 0:\n",
    "            ssim_per_cond = np.asarray(ssim_per_cond)\n",
    "            ssim_values.append(ssim_per_cond.mean())\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        pbar.set_postfix(SSIM_per_cond=ssim_per_cond.mean())\n",
    "\n",
    "ssim_values = np.asarray(ssim_values)\n",
    "ssim.cpu()\n",
    "\n",
    "\n",
    "print(f\"\\033[31m mean SSIM = {ssim_values.mean()}\\033[0m\")\n",
    "\n",
    "if plot:\n",
    "    plt.plot(ssim_values, \"o-\")\n",
    "    plt.show()\n",
    "    plt.clf()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PSNR score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PSNR Evaluation: 100%|██████████| 847/847 [00:06<00:00, 129.19it/s, PSNR_per_cond=28.5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m mean PSNR = 30.076366424560547\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "psnr = PSNR()   # input: (N, 3, H, W)\n",
    "psnr.cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    psnr_values = list()\n",
    "    pbar = tqdm(pred_samples_list, desc=\"PSNR Evaluation\")\n",
    "    for pred_per_cond in pbar:  \n",
    "        if pred_per_cond[0:1].sum()==0:     # prevent Division by Zero \n",
    "            continue\n",
    "        psnr_per_cond = list() \n",
    "        for i in range(1, num_samples):\n",
    "            if pred_per_cond[i:i+1].sum()==0:   # prevent Division by Zero \n",
    "                continue\n",
    "            if (pred_per_cond[i:i+1] == pred_per_cond[0:1]).all():  # prevent Infinate\n",
    "                continue\n",
    "            psnr.update(pred_per_cond[i:i+1].float(), pred_per_cond[0:1].float())\n",
    "            psnr_i = psnr.compute().cpu()\n",
    "            psnr.reset()\n",
    "\n",
    "            psnr_per_cond.append(psnr_i)\n",
    "        if len(psnr_per_cond) > 0:\n",
    "            psnr_per_cond = np.asarray(psnr_per_cond)\n",
    "            psnr_values.append(psnr_per_cond.mean())\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "\n",
    "        pbar.set_postfix(PSNR_per_cond=sum(psnr_per_cond)/len(psnr_per_cond))\n",
    "    \n",
    "psnr.cpu()\n",
    "psnr_values = np.asarray(psnr_values)\n",
    "\n",
    "\n",
    "print(f\"\\033[31m mean PSNR = {psnr_values.mean()}\\033[0m\")\n",
    "\n",
    "if plot:\n",
    "    plt.plot(psnr_values, \"o-\")\n",
    "    plt.show()\n",
    "    plt.clf()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LPIPS socre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LPIPS Evaluation: 100%|██████████| 9/9 [00:03<00:00,  2.37it/s, lpips_score=0.0225]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m mean LPIPS = 0.021929613625009853\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lpips = LPIPS() # input: (N, 3, H, W), [-1, 1], float32\n",
    "lpips.cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    lpips_values = list()\n",
    "    pbar = tqdm(pred_test_set_list[1:], desc=\"LPIPS Evaluation\")\n",
    "    for pred_test_set in pbar:\n",
    "        pred_reference = (pred_test_set_list[0]/255.) *2-1\n",
    "        pred_set = (pred_test_set/255.) *2-1\n",
    "\n",
    "        pred_reference_dataloader = DataLoader(LPIPSDataset(pred_reference), batch_size=50, shuffle=False, drop_last=False)\n",
    "        pred_set_dataloader = DataLoader(LPIPSDataset(pred_set), batch_size=50, shuffle=False, drop_last=False)\n",
    "        lpips_values_per_test = list()\n",
    "        for pred_reference_batch, pred_set_batch in zip(pred_reference_dataloader, pred_set_dataloader):\n",
    "            lpips.update(pred_reference_batch, pred_set_batch)\n",
    "            lpips_score = lpips.compute().cpu() \n",
    "            lpips.reset()\n",
    "            lpips_values_per_test.append(lpips_score)\n",
    "        lpips_values_per_test_mean = np.asarray(lpips_values_per_test).mean()\n",
    "        lpips_values.append(lpips_values_per_test_mean)\n",
    "        pbar.set_postfix(dict(lpips_score=lpips_values_per_test_mean))\n",
    "\n",
    "lpips.cpu()\n",
    "\n",
    "\n",
    "print(f\"\\033[31m mean LPIPS = {sum(lpips_values)/len(lpips_values)}\\033[0m\")\n",
    "\n",
    "if plot:\n",
    "    plt.plot(lpips_values, \"o-\")\n",
    "    plt.show()\n",
    "    plt.clf()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ldm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
